from openai import OpenAI
import json


class LLMPlugin:
    def __init__(self):
        # read pretrain prompt from pretrain_prompt.txt
        with open('pretrain_prompt.txt', 'r') as f:
            self._pretrain_prompt = f.read()

        # read LLMPlugin settings
        with open('../settings.json') as f:
            data = json.load(f)
            self.model = data['LLMPlugin']['model']
            self.messages = [{"role": "system", "content": self._pretrain_prompt}]
            self.cfile = data['ToolConfig']['module']

        with open(self.cfile) as f:
            self.c_content = f.read()
            self.messages.append({"role": "user", "content": self.c_content})

    def generate(self):
        client = OpenAI()
        response = client.chat.completions.create(
            model=self.model,
            messages=self.messages,
        )
        return response.choices[0].message


if __name__ == "__main__":
    print("\n====================\nContent below is generated by LLMPlugin\n====================\n")
    plugin = LLMPlugin()
    print(plugin.generate())
